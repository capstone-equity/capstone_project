---
title: "brain_data_clean"
author: "Yanchi Liu"
date: "2024-11-13"
output: html_document
---

```{r conflicts}
options(conflicts.policy = "depends.ok")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true")
tidymodels_conflictRules()
```

```{r}
#| message: false
#| warning: false
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_plots.R?raw=true")
```

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)

theme_set(theme_classic()) 
library(janitor, include.only = "clean_names") # <1>
library(cowplot, include.only = "plot_grid") # <2> 
library(kableExtra, exclude = "group_rows") # you may or may not use this one!
library(tidyverse) # for general data wrangling
library(tidymodels) # for modeling
library(dplyr)


path_data <- ""
```

```{r}
getwd()
data_all <- read.csv(here::here(path_data, "Brain.csv")) |> 
  glimpse()
```


# Rename Selected Columns & remove the data which publication year is earlier 2009
```{r}
# while control all language as English, rename selected columns
new_data <- data_all |>
  select(AU, PY, DT, TC, Z9, C1, C3, FU) |> 
    rename(
    brain_author_name = AU,
    brain_publication_year = PY,
    brain_document_type = DT,
    brain_times_cited_wos = TC,
    brain_times_cited_all = Z9,
    brain_address = C1,
    brain_affiliation = C3,
    brain_funding_orgs = FU
  ) 

# remove publication year before 2019

new_data <- new_data |>
  filter(brain_publication_year >= 2009) |>
  glimpse()


```
# Check if there are any NA's
```{r}
new_data |> 
  skim_some() |> 
  select(skim_variable, n_missing, complete_rate)
```

# Check specific na's 
```{r}

missing_brain_affiliation <- which(is.na(new_data$brain_affiliation))
missing_brain_affiliation

```

# Coco changed: Remove NA's for variable "brain_address"
```{r}
new_data <- new_data |> 
  filter(!is.na(brain_address))

new_data |> 
  skim_some() |> 
  select(skim_variable, n_missing, complete_rate)
```

# Recode funding_orgs to 0: NA(no value/fundings) and 1: have values(fundings)
```{r}
new_data <- new_data |> 
  mutate(brain_funding_orgs_binary = if_else(is.na(brain_funding_orgs), 0, 1))
```

# Adding avriable: "author_count" from author_name 
```{r}
new_data$brain_author_count <- sapply(strsplit(as.character(new_data$brain_author_name), ";"), length)
new_data


```

# Data Visulization to see the relationship between "brain_funding_orgs_binary" and "brain_author_count"
```{r}
ggplot(new_data, aes(x = as.factor(brain_funding_orgs_binary), y = brain_author_count)) +
  geom_boxplot(fill = "lightblue") +
  labs(
    title = "Relationship between Funding Presence and Author Count",
    x = "Funding Presence (1 = Has Funding, 0 = No Funding)",
    y = "Author Count"
  ) +
  theme_minimal()

# Calculate the average author count for each funding group
author_funding_summary <- new_data |>
  group_by(brain_funding_orgs_binary) |>
  summarise(avg_author_count = mean(brain_author_count, na.rm = TRUE))

# Create a bar plot
ggplot(author_funding_summary, aes(x = as.factor(brain_funding_orgs_binary), y = avg_author_count, fill = as.factor(brain_funding_orgs_binary))) +
  geom_bar(stat = "identity", width = 0.6) +
  labs(
    title = "Average Author Count by Funding Presence",
    x = "Funding Presence (1 = Has Funding, 0 = No Funding)",
    y = "Average Author Count"
  ) +
  scale_fill_manual(values = c("0" = "lightgray", "1" = "steelblue"), name = "Funding Presence") +
  theme_minimal()
```

# Remove brackets in 'brain_address' and form it into a new column called 'brain_extracted_address'
```{r}

new_data <- new_data |>
  mutate(brain_extracted_address = str_remove_all(brain_address, "\\[.*?\\]"))

```

# rotate through every segment in 'brain_extracted_last', split each by commas, and remove everything in the segment except the last 
```{r}
new_data <- new_data |>
  mutate(
    brain_extracted_last = brain_extracted_address |>
      str_split(";"))

new_data <- new_data |> 
  mutate(brain_extracted_last = sapply(brain_extracted_last, function(x) {
    # Split the string by semicolons first to handle multiple segments
    segments <- unlist(strsplit(x, ";\\s*"))
    
    # For each segment, split by commas and keep only the last part
    cleaned_segments <- sapply(segments, function(seg) {
      parts <- unlist(strsplit(seg, ",\\s*"))
      tail(parts, 1) # Extract the last part
    })
    
    # Combine the cleaned segments back into a single string with semicolons
    paste(cleaned_segments, collapse = "; ")
  }))

```


# Using 'countrycode' and 'countries' packages to identify address and form into 'brain_extracted_country' column (BOOST VERSION -- ADDING PARALLEL PROCESSING)
```{r}
library(countrycode)
library(countries)
library(furrr)
countrycode(c('USA'), origin = 'iso3c', destination = 'cown')

all_country <- countryname_dict %>%
  filter(grepl('[A-Za-z]', country.name.en)) %>% # Filter out non-ASCII country names
  pull(country.name.en) %>%                      # Convert to a vector
  tolower()                                      # Convert to lower-case

# Create a regex pattern to match any country name
pattern <- str_c(all_country, collapse = '|')

# Using Parallel processing 
plan(multisession, workers = 8) # Use 8 cores to process data


# Assuming 'new_data' is your data frame and 'brain_extracted_last' is the column containing addresses
new_data <- new_data |>
  mutate(brain_extracted_last = str_replace_all(brain_extracted_last, "USA", "United States of America"),
         brain_extracted_last = str_replace_all(brain_extracted_last, "England", "United Kingdom"),
         brain_extracted_last = str_replace_all(brain_extracted_last, "Scotland", "United Kingdom"),
         brain_extracted_last = str_replace_all(brain_extracted_last, "Wales", "United Kingdom")) |> 
  # Extract country name matches
  # mutate(brain_extracted_country = str_extract_all(tolower(brain_address), pattern))
  
  # Use "future_map" function to extract country name matches
  mutate(brain_extracted_country = future_map(brain_extracted_last, ~ str_extract_all(tolower(.x), pattern)))
```


# Remove "list(c ())" in "brain_extracted_country" 
```{r}
new_data <- new_data |>
  mutate(brain_extracted_country = sapply(brain_extracted_country, function(x) {
    if (length(x) == 0 || is.null(x)) {
      return(NA)  # Replace empty lists with NA
    } else {
      return(paste(unique(x), collapse = "; "))  # Flatten list and remove duplicates, if needed
    }
  }))


new_data$brain_extracted_country <- gsub('c\\(|"|\\)', '', new_data$brain_extracted_country)

```

# Check specific NA's 
```{r}
missing_brain_extracted_country <- which(is.na(new_data$brain_extracted_country))
missing_brain_extracted_country
```

# Check if there are any NA's
```{r}
new_data |> 
  skim_some() |> 
  select(skim_variable, n_missing, complete_rate)
```


# Remove repeated countries 'brain_extracted_country
```{r}
# Remove duplicates within each row of 'brain_extracted_country'
new_data$brain_extracted_country <- sapply(new_data$brain_extracted_country, function(x) {
  # Split the string by commas
  countries <- unlist(strsplit(x, ",\\s*"))
  # Keep only unique countries
  unique_countries <- unique(countries)
  # Combine back into a single string
  paste(unique_countries, collapse = ", ")
})

# Convert back to a data frame if needed
new_data <- as.data.frame(new_data)
```

# Check if there are still any repeated contries in 'brain_extracted_country'
```{r}
# Function to check for repeated countries
check_repeats <- function(x) {
  countries <- unlist(strsplit(x, ";"))  # Split the string by semicolon
  unique_countries <- unique(trimws(countries))  # Remove duplicates and extra spaces
  return(length(countries) != length(unique_countries))  # Check if lengths differ
}

# Apply the function to check for repeats in 'brain_extracted_country'
repeated_rows <- which(sapply(new_data$brain_extracted_country, check_repeats))

# Output the result
if (length(repeated_rows) > 0) {
  cat("Rows with repeated countries in 'brain_extracted_country':\n")
  print(new_data$brain_extracted_country[repeated_rows])
} else {
  cat("No repeated countries found in 'brain_extracted_country'.\n")
}
```

# Add a new column "brain_country_binary": more than 1 country = 1, only one country = 0
```{r}
new_data$brain_country_binary <- sapply(new_data$brain_extracted_country, function(x) {
  # Split the countries by semicolon and remove any extra white space
  countries <- unique(trimws(unlist(strsplit(x, ","))))
  # Check if there are more than 1 unique country
  if (length(countries) > 1) {
    return(1)  # More than one country
  } else {
    return(0)  # Only one country
  }
})

# View the modified data
View(new_data)
```

# Add a new column "brain_country_count"
```{r}
# Counts for the affiliation from brain_affiliation
new_data <- new_data |> 
  mutate(
    brain_country_count = str_count(brain_extracted_country, ",") + 1 # Count semicolons and add 1
  )
```

# Visuliztion for "brain_country_count"
```{r}
hist(new_data$brain_country_count)
```

# Check
```{r}
new_data |> janitor::tabyl(brain_country_count)
```


# Save it as .RDS
```{r}
getwd()
saveRDS(new_data, file = "/Users/ycl/Desktop/capstone1/brain_data_clean.rds")
```

# Read .RDS
```{r}
new_data <- readRDS("/Users/ycl/Desktop/capstone1/brain_data_clean.rds")
view(new_data)
skimr::skim(new_data)
```
# Check if there are any NA's in dataset agian
```{r}
new_data |> 
  skim_some() |> 
  select(skim_variable, n_missing, complete_rate)
```

# Remove repeated affiliation in 'brain_affiliation'
```{r}
# Remove repeated affiliations in 'brain_affiliation'
new_data$brain_affiliation <- sapply(new_data$brain_affiliation, function(x) {
  # Split the affiliations by a delimiter (e.g., ";")
  affiliations <- unlist(strsplit(x, ";"))
  # Remove duplicates and extra spaces
  unique_affiliations <- unique(trimws(affiliations))
  # Combine unique affiliations back into a single string
  return(paste(unique_affiliations, collapse = "; "))
})
```

# Check if there are any repeated affiliation in 'brain_affliation'
```{r}
# Check if there are repeated affiliations in 'brain_affiliation'
repeated_affiliations <- sapply(new_data$brain_affiliation, function(x) {
  # Split the affiliations by a delimiter (e.g., ";")
  affiliations <- unlist(strsplit(x, ";"))
  # Remove extra spaces
  affiliations <- trimws(affiliations)
  # Check if any duplicates exist
  return(length(affiliations) > length(unique(affiliations)))
})

# Find rows with repeated affiliations
rows_with_repeats <- which(repeated_affiliations)

# Display the rows with repeated affiliations
new_data[rows_with_repeats, ]
```

# Search from "afiliation" column, create a new list of strings contains "university" and "system" called "system_affiliations"
```{r}

# Extract unique parts containing "system" from the semicolon-separated affiliations
system_affiliations <- new_data |>
  filter(str_detect(brain_affiliation, regex("system", ignore_case = TRUE))) |> # Filter rows with "system"
  pull(brain_affiliation) |> # Extract affiliation column
  str_split(";") |> # Split by semicolon
  unlist() |> # Flatten into a single vector
  str_trim() # Trim whitespace

# Keep only parts containing "system" and get unique values
system_affiliations <- unique(system_affiliations[str_detect(system_affiliations, regex("system", ignore_case = TRUE))])

# Print the result
print(system_affiliations)

```

# In "affiliation" column, remove same strings pattern from "system_affiliations", and hard coding for SUNY and CUNY system.
```{r}

# Combine the list into a single pattern, separated by |
pattern <- paste(system_affiliations, collapse = "|")

# Use the pattern to remove all matches in the brain_affiliation column
new_data <- new_data |>
  mutate(brain_affiliation = str_remove_all(brain_affiliation, pattern = paste0("(", pattern, ");?")))



# Remove the specific string from the brain_affiliation column
new_data <- new_data |>
  mutate(brain_affiliation = str_remove(brain_affiliation, "State University of New York \\(SUNY\\) System;|City University of New York \\(CUNY\\) System;|Vet Affairs Puget Sound Health Care System;|Atlantic Health System;|VA Boston Healthcare System;|Children's National Health System;|VA Connecticut Healthcare System;|Sinai Health System Toronto;"))

# View the result
head(new_data)

```

# based on "brain_affiliation", create new column "brain_no_duplicate_affiliation"
```{r}
# Remove duplicate brain_affiliation within each semicolon-separated entry
new_data <- new_data |>
  mutate(brain_no_duplicate_affiliation = brain_affiliation |>
           # Split brain_affiliation by ";", remove duplicates, and recombine
           str_split(";") |>
           lapply(function(x) unique(trimws(x))) |>
           sapply(paste, collapse = "; "))
```

# check and count if there are still duplicate affiliations
```{r}
brain_no_duplicate_affiliations <- new_data |>
  group_by(brain_affiliation) |>
  filter(n() > 1) |>
  summarise(count = n())

print(brain_no_duplicate_affiliations)
```

# Creat "brain_affiliation_binary" 0:One affliation; 1: more than one affliation
```{r}
new_data <- new_data |> 
  mutate(brain_affiliation_binary = if_else(
    str_count(brain_affiliation, ";") > 0, 1, 0
  ))
```

# Visulization for "brain_affiliation_binary"
```{r}
hist(new_data$brain_affiliation_binary)
```
# Check
```{r}
new_data |> janitor::tabyl(brain_affiliation_binary)
```


# Visulization for not recode as 0 and 1
```{r}
# Counts for the affiliation from brain_affiliation
new_data <- new_data |> 
  mutate(
    brain_affiliation_count = str_count(brain_affiliation, ";") + 1 # Count semicolons and add 1
  )

hist(new_data$brain_affiliation_count)
```
# Check
```{r}
new_data |> janitor::tabyl(brain_affiliation_count)
```

# Manual affiliation from address
```{r}
new_data <- new_data |> 
  mutate(
    # brain_manual_affiliation = str_remove_all(brain_address, "\\[.*?\\]"),
    brain_manual_affiliation = str_split(brain_extracted_address, ";"),
    brain_manual_affiliation = map(brain_manual_affiliation,
                                  ~ map_chr(.x, ~ str_trim(str_split(.x, ",")[[1]][1]))),
    brain_manual_affiliation = map(brain_manual_affiliation, unlist),
    brain_manual_affiliation = map(brain_manual_affiliation, unique),
    brain_manual_affiliation_count = map(brain_manual_affiliation, length),
    brain_manual_affiliation_binary = if_else(brain_manual_affiliation_count == 1, 0, 1)
  )

new_data |> 
  filter(brain_manual_affiliation_count != brain_affiliation_count) |> 
  select(brain_address, brain_affiliation, brain_manual_affiliation) |>
  glimpse()
```

# Remove the raw affiliation
```{r}
new_data <- new_data |> 
  mutate(
    brain_no_duplicate_affiliation = brain_manual_affiliation,
    brain_affiliation_binary = brain_manual_affiliation_binary,
    brain_affiliation_count = brain_manual_affiliation_count
  ) |> 
  select(-brain_manual_affiliation, -brain_manual_affiliation_binary,
         -brain_manual_affiliation_count)
```

# Remove unnecessary columns, reorder and rename columns
```{r}
brain_data <- new_data |>
  select(brain_author_name, brain_author_count, brain_publication_year, brain_document_type, brain_no_duplicate_affiliation, brain_affiliation_binary, brain_affiliation_count, brain_extracted_address, brain_extracted_country, brain_country_binary, brain_country_count, brain_times_cited_all, brain_funding_orgs, brain_funding_orgs_binary) |>
  rename(
    author_name = brain_author_name,
    author_count = brain_author_count,
    publication_year = brain_publication_year,
    document_type = brain_document_type,
    no_duplicate_affiliation = brain_no_duplicate_affiliation,
    affiliation_binary = brain_affiliation_binary,
    affiliation_count = brain_affiliation_count,
    extracted_address = brain_extracted_address,
    extracted_country = brain_extracted_country,
    country_binary = brain_country_binary,
    country_count = brain_country_count,
    times_cited = brain_times_cited_all,
    founding_orgs = brain_funding_orgs,
    founding_orgs_binary = brain_funding_orgs_binary
  ) |>
  glimpse()
```
# clean document_type: delete "proceedings paper" and "retracted article":
```{r}
brain_data <- brain_data |>
  filter(!grepl("Proceedings Paper", document_type) &
         !grepl("Retracted Publication", document_type))


```

# Write .csv
```{r}
brain_data <- brain_data |>
  mutate(no_duplicate_affiliation = sapply(no_duplicate_affiliation, function(x) {
    if (length(x) == 0 || is.null(x)) {
      return(NA)  # Replace empty lists with NA
    } else {
      return(paste(unique(x), collapse = "; "))  # Flatten list and remove duplicates, if needed
    }
  })) |> 
  mutate(affiliation_count = unlist(affiliation_count)) |> 
  glimpse()
```

```{r}
getwd()
write_csv(brain_data, "brain_cleaned.csv")
```



