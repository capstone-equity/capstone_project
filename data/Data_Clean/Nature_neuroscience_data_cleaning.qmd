---
title: "Nature_neuroscience_data_clean"
author: "Yanchi Liu"
date: "2024-11-10"
output: html_document
---

```{r conflicts}
options(conflicts.policy = "depends.ok")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true")
tidymodels_conflictRules()
```

```{r}
#| message: false
#| warning: false
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_plots.R?raw=true")
```

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)

theme_set(theme_classic()) 
library(janitor, include.only = "clean_names") # <1>
library(cowplot, include.only = "plot_grid") # <2> 
library(kableExtra, exclude = "group_rows") # you may or may not use this one!
library(tidyverse) # for general data wrangling
library(tidymodels) # for modeling
library(dplyr)


path_data <- ""
```

```{r}
getwd()
data_all <- read.csv(here::here(path_data, "Nature_Neuroscience.csv")) |> 
  glimpse()
```

# Rename Selected Columns & remove the data which publication year is earlier 2009
```{r}
# while control all language as English, rename selected columns
new_data <- data_all |>
  select(AU, PY, DT, TC, Z9, C1, C3, FU) |> 
    rename(
    nature_author_name = AU,
    nature_publication_year = PY,
    nature_document_type = DT,
    nature_times_cited_wos = TC,
    nature_times_cited_all = Z9,
    nature_address = C1,
    nature_affiliation = C3,
    nature_funding_orgs = FU
  ) 

# remove publication year before 2019

new_data <- new_data |>
  filter(nature_publication_year >= 2009) |>
  glimpse()


```

# Check if there are any NA's in nature dataset
```{r}
new_data |> 
  skim_some() |> 
  select(skim_variable, n_missing, complete_rate)
```


# Recode nature_funding_orgs to 0: NA(no value/fundings) and 1: have values(fundings)
```{r}
new_data <- new_data |> 
  mutate(nature_funding_orgs_binary = if_else(is.na(nature_funding_orgs), 0, 1))
```

# Adding avriable: "author_count" from author_name 
```{r}
new_data$nature_author_count <- sapply(strsplit(as.character(new_data$nature_author_name), ";"), length)
new_data
```

# Remove brackets in 'brain_address' and form it into a new column called 'nature_extracted_address'
```{r}

new_data <- new_data |>
  mutate(nature_extracted_address = str_remove_all(nature_address, "\\[.*?\\]"))

```


# rotate through every segment in 'nature_extracted_last', split each by commas, and remove everything in the segment except the last 

```{r}
new_data <- new_data |>
  mutate(
    nature_extracted_last = nature_extracted_address |>
      str_split(";"))

new_data <- new_data |> 
  mutate(nature_extracted_last = sapply(nature_extracted_last, function(x) {
    # Split the string by semicolons first to handle multiple segments
    segments <- unlist(strsplit(x, ";\\s*"))
    
    # For each segment, split by commas and keep only the last part
    cleaned_segments <- sapply(segments, function(seg) {
      parts <- unlist(strsplit(seg, ",\\s*"))
      tail(parts, 1) # Extract the last part
    })
    
    # Combine the cleaned segments back into a single string with semicolons
    paste(cleaned_segments, collapse = "; ")
  }))

```

# Using 'countrycode' and 'countries' packages to identify address and form into 'nature_extracted_country' column (BOOST VERSION -- ADDING PARALLEL PROCESSING)
```{r}
library(countrycode)
library(countries)
library(furrr)
countrycode(c('USA'), origin = 'iso3c', destination = 'cown')

all_country <- countryname_dict %>%
  filter(grepl('[A-Za-z]', country.name.en)) %>% # Filter out non-ASCII country names
  pull(country.name.en) %>%                      # Convert to a vector
  tolower()                                      # Convert to lower-case

# Create a regex pattern to match any country name
pattern <- str_c(all_country, collapse = '|')

# Using Parallel processing 
plan(multisession, workers = 8) # Use 8 cores to process data


# Assuming 'new_data' is your data frame and 'brain_extracted_last' is the column containing addresses
new_data <- new_data |>
  mutate(nature_extracted_last = str_replace_all(nature_extracted_last, "USA", "United States of America"),
         nature_extracted_last = str_replace_all(nature_extracted_last, "England", "United Kingdom"),
         nature_extracted_last = str_replace_all(nature_extracted_last, "Scotland", "United Kingdom"),
         nature_extracted_last = str_replace_all(nature_extracted_last, "Wales", "United Kingdom")) |> 
  # Extract country name matches
  # mutate(brain_extracted_country = str_extract_all(tolower(brain_address), pattern))
  
  # Use "future_map" function to extract country name matches
  mutate(nature_extracted_country = future_map(nature_extracted_last, ~ str_extract_all(tolower(.x), pattern)))
```

# Remove "list(c ())" in "nature_extracted_country" 
```{r}
new_data <- new_data |>
  mutate(nature_extracted_country = sapply(nature_extracted_country, function(x) {
    if (length(x) == 0 || is.null(x)) {
      return(NA)  # Replace empty lists with NA
    } else {
      return(paste(unique(x), collapse = "; "))  # Flatten list and remove duplicates, if needed
    }
  }))


new_data$nature_extracted_country <- gsub('c\\(|"|\\)', '', new_data$nature_extracted_country)

```

# Check if there are any NA's
```{r}
new_data |> 
  skim_some() |> 
  select(skim_variable, n_missing, complete_rate)
```

# Coco changed: Remove NAs
```{r}
new_data <- new_data |>
  mutate(id = 1:n()) |>
  select(id, everything())|>
  filter(!is.na(nature_address)) |> # Remove NA
  glimpse()
```

# Recode repeated country name in 'nature_extracted_country'
```{r}
# Remove duplicates within each row of 'nature_extracted_country'
new_data$nature_extracted_country <- sapply(new_data$nature_extracted_country, function(x) {
  # Split the string by commas
  countries <- unlist(strsplit(x, ",\\s*"))
  # Keep only unique countries
  unique_countries <- unique(countries)
  # Combine back into a single string
  paste(unique_countries, collapse = ", ")
})

# Convert back to a data frame if needed
new_data <- as.data.frame(new_data)
```


# Check if there are still any repeated contries in 'nature_extracted_country'
```{r}
# Function to check for repeated countries
check_repeats <- function(x) {
  countries <- unlist(strsplit(x, ";"))  # Split the string by semicolon
  unique_countries <- unique(trimws(countries))  # Remove duplicates and extra spaces
  return(length(countries) != length(unique_countries))  # Check if lengths differ
}

# Apply the function to check for repeats in 'nature_extracted_country'
repeated_rows <- which(sapply(new_data$nature_extracted_country, check_repeats))

# Output the result
if (length(repeated_rows) > 0) {
  cat("Rows with repeated countries in 'nature_extracted_country':\n")
  print(new_data$nature_extracted_country[repeated_rows])
} else {
  cat("No repeated countries found in 'nature_extracted_country'.\n")
}
```

# Add a new column "nature_country_binary": more than 1 country = 1, only one country = 0
```{r}
new_data$nature_country_binary <- sapply(new_data$nature_extracted_country, function(x) {
  # Split the countries by semicolon and remove any extra white space
  countries <- unique(trimws(unlist(strsplit(x, ","))))
  # Check if there are more than 1 unique country
  if (length(countries) > 1) {
    return(1)  # More than one country
  } else {
    return(0)  # Only one country
  }
})

# View the modified data
View(new_data)
```

# Add a new column "nature_country_count"
```{r}
# Counts for the affiliation from brain_affiliation
new_data <- new_data |> 
  mutate(
    nature_country_count = str_count(nature_extracted_country, ",") + 1 # Count semicolons and add 1
  )
```

# Visuliztion for "nature_country_count"
```{r}
hist(new_data$nature_country_count)
```

# Check
```{r}
new_data |> janitor::tabyl(nature_country_count)
```

# save as .RDS
```{r}
getwd()
saveRDS(new_data, file = "/Users/ycl/Desktop/capstone1/Nature_neuroscience_data_clean.rds")
```

# Read in RDS
```{r}
new_data <- readRDS("/Users/ycl/Desktop/capstone1/Nature_neuroscience_data_clean.rds")
view(new_data)
skimr::skim(new_data)
```

# Check if there are any NA's in dataset agian
```{r}
new_data |> 
  skim_some() |> 
  select(skim_variable, n_missing, complete_rate)
```

# Remove repeated affiliation in 'nature_affiliation'
```{r}
# Remove repeated affiliations in 'nature_affiliation'
new_data$nature_affiliation <- sapply(new_data$nature_affiliation, function(x) {
  # Split the affiliations by a delimiter (e.g., ";")
  affiliations <- unlist(strsplit(x, ";"))
  # Remove duplicates and extra spaces
  unique_affiliations <- unique(trimws(affiliations))
  # Combine unique affiliations back into a single string
  return(paste(unique_affiliations, collapse = "; "))
})
```

# Check if there are any repeated affiliation in 'nature_affliation'
```{r}
# Check if there are repeated affiliations in 'brain_affiliation'
repeated_affiliations <- sapply(new_data$nature_affiliation, function(x) {
  # Split the affiliations by a delimiter (e.g., ";")
  affiliations <- unlist(strsplit(x, ";"))
  # Remove extra spaces
  affiliations <- trimws(affiliations)
  # Check if any duplicates exist
  return(length(affiliations) > length(unique(affiliations)))
})

# Find rows with repeated affiliations
rows_with_repeats <- which(repeated_affiliations)

# Display the rows with repeated affiliations
new_data[rows_with_repeats, ]
```

# Search from "afiliation" column, create a new list of strings contains "university" and "system" called "system_affiliations"
```{r}

# Extract unique parts containing "system" from the semicolon-separated affiliations
system_affiliations <- new_data |>
  filter(str_detect(nature_affiliation, regex("system", ignore_case = TRUE))) |> # Filter rows with "system"
  pull(nature_affiliation) |> # Extract affiliation column
  str_split(";") |> # Split by semicolon
  unlist() |> # Flatten into a single vector
  str_trim() # Trim whitespace

# Keep only parts containing "system" and get unique values
system_affiliations <- unique(system_affiliations[str_detect(system_affiliations, regex("system", ignore_case = TRUE))])

# Print the result
print(system_affiliations)

```

# In "affiliation" column, remove same strings pattern from "system_affiliations", and hard coding for SUNY and CUNY system.
```{r}

# Combine the list into a single pattern, separated by |
pattern <- paste(system_affiliations, collapse = "|")

# Use the pattern to remove all matches in the brain_affiliation column
new_data <- new_data |>
  mutate(nature_affiliation = str_remove_all(nature_affiliation, pattern = paste0("(", pattern, ");?")))



# Remove the specific string from the brain_affiliation column
new_data <- new_data |>
  mutate(nature_affiliation = str_remove(nature_affiliation, "State University of New York \\(SUNY\\) System;|City University of New York \\(CUNY\\) System;|Vet Affairs Puget Sound Health Care System;|Atlantic Health System;|VA Boston Healthcare System;|Children's National Health System;|VA Connecticut Healthcare System;|Sinai Health System Toronto;"))

# View the result
head(new_data)

```

# based on "nature_affiliation", create new column "nature_no_duplicate_affiliation"
```{r}
# Remove duplicate brain_affiliation within each semicolon-separated entry
new_data <- new_data |>
  mutate(nature_no_duplicate_affiliation = nature_affiliation |>
           # Split brain_affiliation by ";", remove duplicates, and recombine
           str_split(";") |>
           lapply(function(x) unique(trimws(x))) |>
           sapply(paste, collapse = "; "))
```


# check and count if there are still duplicate affiliations
```{r}
nature_no_duplicate_affiliations <- new_data |>
  group_by(nature_affiliation) |>
  filter(n() > 1) |>
  summarise(count = n())

print(nature_no_duplicate_affiliations)
```

# Creat "nature_affiliation_binary" 0: One affliation; 1: more than one affliation
```{r}
new_data <- new_data |> 
  mutate(nature_affiliation_binary = if_else(
    str_count(nature_affiliation, ";") > 0, 1, 0
  ))
```

# Visulization for "nature_affiliation_binary"
```{r}
hist(new_data$nature_affiliation_binary)
```

# Check
```{r}
new_data |> janitor::tabyl(nature_affiliation_binary)
```

# Visulization for not recode as 0 and 1
```{r}
# Counts for the affiliation from nature_affiliation
new_data <- new_data |> 
  mutate(
    nature_affiliation_count = str_count(nature_affiliation, ";") + 1 # Count semicolons and add 1
  )

hist(new_data$nature_affiliation_count)
```

# Check
```{r}
new_data |> janitor::tabyl(nature_affiliation_count)
```

# Manual affiliation from address
```{r}
new_data <- new_data |> 
  mutate(
    # nature_manual_affiliation = str_remove_all(nature_address, "\\[.*?\\]"),
    nature_manual_affiliation = str_split(nature_extracted_address, ";"),
    nature_manual_affiliation = map(nature_manual_affiliation,
                                  ~ map_chr(.x, ~ str_trim(str_split(.x, ",")[[1]][1]))),
    nature_manual_affiliation = map(nature_manual_affiliation, unlist),
    nature_manual_affiliation = map(nature_manual_affiliation, unique),
    nature_manual_affiliation_count = map(nature_manual_affiliation, length),
    nature_manual_affiliation_binary = if_else(nature_manual_affiliation_count == 1, 0, 1)
  )

new_data |> 
  filter(nature_manual_affiliation_count != nature_affiliation_count) |> 
  select(nature_address, nature_affiliation, nature_manual_affiliation) |> 
  glimpse()
```

# Remove the raw affiliation
```{r}
new_data <- new_data |> 
  mutate(
    nature_no_duplicate_affiliation = nature_manual_affiliation,
    nature_affiliation_binary = nature_manual_affiliation_binary,
    nature_affiliation_count = nature_manual_affiliation_count
  ) |> 
  select(-nature_manual_affiliation, -nature_manual_affiliation_binary,
         -nature_manual_affiliation_count)
```

# Remove unnecessary columns, reorder and rename columns
```{r}
nature_data <- new_data |>
  select(nature_author_name, nature_author_count, nature_publication_year, nature_document_type, nature_no_duplicate_affiliation, nature_affiliation_binary, nature_affiliation_count, nature_extracted_address, nature_extracted_country, nature_country_binary, nature_country_count, nature_times_cited_all, nature_funding_orgs, nature_funding_orgs_binary) |>
  rename(
    author_name = nature_author_name,
    author_count = nature_author_count,
    publication_year = nature_publication_year,
    document_type = nature_document_type,
    no_duplicate_affiliation = nature_no_duplicate_affiliation,
    affiliation_binary = nature_affiliation_binary,
    affiliation_count = nature_affiliation_count,
    extracted_address = nature_extracted_address,
    extracted_country = nature_extracted_country,
    country_binary = nature_country_binary,
    country_count = nature_country_count,
    times_cited = nature_times_cited_all,
    founding_orgs = nature_funding_orgs,
    founding_orgs_binary = nature_funding_orgs_binary
  ) |>
  glimpse()
```

# clean document_type: delete "proceedings paper" and "retracted article":
```{r}
nature_data <- nature_data |>
  filter(!grepl("Proceedings Paper", document_type) &
         !grepl("Retracted Publication", document_type))


```


# Write csv
```{r}
nature_data <- nature_data |>
  mutate(no_duplicate_affiliation = sapply(no_duplicate_affiliation, function(x) {
    if (length(x) == 0 || is.null(x)) {
      return(NA)  # Replace empty lists with NA
    } else {
      return(paste(unique(x), collapse = "; "))  # Flatten list and remove duplicates, if needed
    }
  })) |> 
  mutate(affiliation_count = unlist(affiliation_count)) |> 
  glimpse()
```

```{r}
write_csv(nature_data, "natrue_cleaned.csv")
```







